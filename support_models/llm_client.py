import json
import os
import re
import sys
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from openai import OpenAI

from .scenarios import Scenario, find_best_scenario
from . import SUPPORT_MODELS


_client: Optional[OpenAI] = None


def _get_client() -> OpenAI:
    """
    æ‡’åŠ è½½ OpenAI/GLM å®¢æˆ·ç«¯ï¼Œé¿å…åœ¨æœªé…ç½®ç¯å¢ƒå˜é‡æ—¶è¿‡æ—©æŠ¥é”™ã€‚
    """
    global _client
    if _client is None:
        # base_url = os.environ.get("GLM_BASE_URL")
        # api_key = os.environ.get("GLM_API_KEY")
        base_url = os.environ.get("BASE_URL")
        api_key = os.environ.get("API_KEY")

        if not base_url or not api_key:
            raise RuntimeError(
                "GLM_BASE_URL æˆ– GLM_API_KEY æœªé…ç½®ï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆè“å›¾ã€‚"
            )
        print(
            f"[LLM] åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ base_url={base_url!r}, model={os.environ.get('MODEL_NAME', 'glm-4-flash')!r}",
            file=sys.stderr,
        )
        _client = OpenAI(base_url=base_url, api_key=api_key)
    return _client


@dataclass
class BlueprintResult:
    """
    å¤§æ¨¡å‹ç”Ÿæˆçš„è“å›¾ç»“æœå°è£…ã€‚
    """

    blueprint: Dict[str, Any]
    scenario: Optional[Scenario]
    raw_content: str


@dataclass
class ClassificationResult:
    """
    å¤§æ¨¡å‹å¯¹ä»»åŠ¡æ‰€å±æ”¯æ´æ¨¡å‹çš„åˆ†ç±»ç»“æœã€‚
    """

    model_name: str
    reason: str
    raw_content: str


def _build_prompt(
    model_name: str, task_description: str, scenario: Optional[Scenario]
) -> List[Dict[str, Any]]:
    """
    æ„é€ ç”¨äºå¤§æ¨¡å‹ç”Ÿæˆè“å›¾çš„å¯¹è¯æ¶ˆæ¯ã€‚

    è¿™é‡Œéµå¾ªç°æœ‰ README/base.py ä¸­å®šä¹‰çš„ BLUEPRINT ç»“æ„ï¼š
    - default_focus: str
    - behavior_tree: dict
    - node_insights: dict
    """
    # JSON Schema æ ¼å¼è¯´æ˜
    json_schema_example = """{
  "default_focus": "priority_plan",
  "behavior_tree": {
    "id": "task_parse",
    "label": "ä»»åŠ¡è§£æ",
    "status": "completed",
    "summary": "è§£æä»»åŠ¡æè¿°å¹¶å¯¹æ¥ç›¸å…³æ¸…å•ã€‚",
    "children": [
      {
        "id": "data_clean",
        "label": "æ•°æ®æ¸…æ´—",
        "status": "completed",
        "summary": "èåˆå¤šæºæ•°æ®ã€‚",
        "children": []
      }
    ]
  },
  "node_insights": {
    "task_parse": {
      "title": "ä»»åŠ¡è§£æ",
      "summary": "æŠ½å–ä»»åŠ¡åœ°ç‚¹ã€æ•°é‡ä¸é€šè”æ–¹å¼ï¼Œæ„å»ºç»Ÿä¸€ä»»åŠ¡é¢æ¿ã€‚",
      "key_points": [
        "è¯­ä¹‰è§£æè¯†åˆ«å…³é”®ç»“æ„",
        "ä¸çŸ¥è¯†åº“æ¯”å¯¹æ ‡ç­¾",
        "å‘ä¸‹æ¸¸èŠ‚ç‚¹å¹¿æ’­æ ‡å‡†åŒ–ä»»åŠ¡åŒ…"
      ],
      "knowledge_trace": "é€šè¿‡"ä»»åŠ¡æ–‡æœ¬â†’æ ‡å‡†ä»»åŠ¡æ¨¡æ¿"é“¾è·¯å®šä½åˆ°æ”¯æ´æ¨¡å‹çš„åœºæ™¯å…¥å£ã€‚"
    },
    "priority_plan": {
      "title": "ä¼˜å…ˆçº§æ’åº",
      "summary": "ç»“åˆæŒ‡æ•°ä¸èµ„æºçº¦æŸåŠ¨æ€ç”Ÿæˆæ’åºåˆ—è¡¨ã€‚",
      "key_points": [
        "æŒ‡æ•°è®¡ç®—ï¼šå¤šç»´åº¦æŒ‡æ ‡åŠ æƒ",
        "èµ„æºçº¦æŸï¼šå®æ—¶è¯„ä¼°",
        "åŠ¨æ€é‡æ’ï¼šå˜åŠ¨å³åˆ»åˆ·æ–°åºåˆ—"
      ],
      "knowledge_trace": "ç»¼åˆæŒ‡æ•°ä¸èµ„æºåŒ¹é…é€»è¾‘ï¼Œè¾“å‡ºå®æ—¶æ’åºã€‚",
      "knowledge_graph": {
        "nodes": [
          {"id": "input_data", "label": "è¾“å…¥æ•°æ®", "type": "input"},
          {"id": "calculation", "label": "è®¡ç®—è¿‡ç¨‹", "type": "process"},
          {"id": "result", "label": "æ’åºç»“æœ", "type": "output"}
        ],
        "edges": [
          {"source": "input_data", "target": "calculation"},
          {"source": "calculation", "target": "result"}
        ]
      }
    }
  }
}"""

    # é€šç”¨è¯´æ˜
    base_system_content = (
        "ä½ æ˜¯ä¸€ä¸ªæ”¯æ´æ¨¡å‹æ¨ç†å¯è§†åŒ–ç³»ç»Ÿçš„åç«¯æ¨ç†åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡æè¿°ç”Ÿæˆè¡Œä¸ºæ ‘è“å›¾ã€‚\n\n"
        "ğŸ“‹ è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆä¸¥æ ¼éµå¾ªï¼‰ï¼š\n"
        "1. å¿…é¡»è¾“å‡ºæœ‰æ•ˆçš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```json æˆ– ```ï¼‰ã€‚\n"
        "2. JSON ç»“æ„å¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªé¡¶çº§å­—æ®µï¼š\n"
        "   - default_focus: stringï¼Œé»˜è®¤èšç„¦çš„èŠ‚ç‚¹ IDï¼ˆå¿…é¡»æ˜¯ behavior_tree ä¸­å­˜åœ¨çš„èŠ‚ç‚¹ idï¼‰\n"
        "   - behavior_tree: objectï¼Œè¡Œä¸ºæ ‘æ ¹èŠ‚ç‚¹ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n"
        "     * id: stringï¼ˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼‰\n"
        "     * label: stringï¼ˆç®€ä½“ä¸­æ–‡æ˜¾ç¤ºåç§°ï¼Œå¿…é¡»åŒ…å«å…·ä½“æ•°å€¼ç»“æœï¼‰\n"
        "     * status: stringï¼ˆåªèƒ½æ˜¯ 'pending'ã€'active'ã€'completed' ä¹‹ä¸€ï¼‰\n"
        "     * summary: stringï¼ˆèŠ‚ç‚¹ç®€è¦æè¿°ï¼Œç®€ä½“ä¸­æ–‡ï¼Œå¿…é¡»åŒ…å«å…·ä½“æ•°å€¼è€Œéç©ºæ³›æè¿°ï¼‰\n"
        "     * children: arrayï¼ˆå­èŠ‚ç‚¹æ•°ç»„ï¼Œæ¯ä¸ªå­èŠ‚ç‚¹ç»“æ„ç›¸åŒï¼Œé€’å½’å®šä¹‰ï¼‰\n"
        "   - node_insights: objectï¼ŒèŠ‚ç‚¹æ´å¯Ÿå­—å…¸ï¼Œkey ä¸ºèŠ‚ç‚¹ idï¼Œvalue ä¸ºå¯¹è±¡ï¼ŒåŒ…å«ï¼š\n"
        "     * title: stringï¼ˆæ´å¯Ÿæ ‡é¢˜ï¼Œç®€ä½“ä¸­æ–‡ï¼‰\n"
        "     * summary: stringï¼ˆè¯¦ç»†æè¿°ï¼Œç®€ä½“ä¸­æ–‡ï¼Œå¿…é¡»åŒ…å«å…·ä½“æ•°å€¼è€Œéç©ºæ³›æè¿°ï¼‰\n"
        "     * key_points: array<string>ï¼ˆå…³é”®è¦ç‚¹åˆ—è¡¨ï¼Œ3-5 æ¡ï¼Œç®€ä½“ä¸­æ–‡ï¼Œæ¯æ¡å¿…é¡»åŒ…å«å…·ä½“æ•°å€¼æˆ–è®¡ç®—è¿‡ç¨‹ï¼‰\n"
        "     * knowledge_trace: stringï¼ˆæ¨ç†è¿‡ç¨‹è¯´æ˜ï¼Œç®€ä½“ä¸­æ–‡ï¼Œä½¿ç”¨ç®­å¤´ï¼ˆâ†’ï¼‰è¿æ¥å„ä¸ªæ¨ç†æ­¥éª¤ï¼‰\n"
        "     * knowledge_graph: objectï¼ˆå¯é€‰ï¼Œä»…å…³é”®å†³ç­–èŠ‚ç‚¹éœ€è¦ï¼ŒåŒ…å« nodes å’Œ edgesï¼‰\n"
        "       - nodes: array<{id: string, label: string, type: string}>\n"
        "       - edges: array<{source: string, target: string}>\n\n"
        "3. æ‰€æœ‰æ–‡æœ¬å­—æ®µï¼ˆlabelã€summaryã€titleã€key_pointsã€knowledge_traceã€knowledge_graph.nodes[].labelï¼‰å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚\n"
        "4. status å­—æ®µåªèƒ½æ˜¯ï¼š'pending'ã€'active'ã€'completed' ä¸‰ç§ä¹‹ä¸€ã€‚\n"
        "5. knowledge_graph ä¸­èŠ‚ç‚¹çš„ type å­—æ®µåªèƒ½æ˜¯ï¼š'input'ã€'process'ã€'decision'ã€'output' ä¹‹ä¸€ã€‚\n"
        "6. knowledge_graph çš„ nodes[].label å¿…é¡»åŒ…å«å…·ä½“å‚æ•°ä¿¡æ¯ï¼Œæ ¼å¼ï¼š\"èŠ‚ç‚¹åç§°(å…·ä½“å‚æ•°1, å…·ä½“å‚æ•°2, ...)\"\n"
        "7. knowledge_graph çš„ nodes å’Œ edges å¿…é¡»å½¢æˆæœ‰å‘æ— ç¯å›¾ï¼Œèƒ½å¤Ÿæ¸…æ™°ä½“ç°ä»ä»»åŠ¡è§£æ â†’ æ–¹æ¡ˆè®¾è®¡ â†’ ç»“æœè¾“å‡ºçš„æ¨ç†é“¾æ¡ã€‚\n\n"
        "ğŸŒ³ è¡Œä¸ºæ ‘ç»“æ„è¦æ±‚ï¼ˆå¿…é¡»éµå¾ªï¼‰ï¼š\n"
        "1. è¡Œä¸ºæ ‘å¿…é¡»è‡³å°‘åŒ…å«ä¸¤å±‚ç»“æ„ï¼š\n"
        "   - æ ¹èŠ‚ç‚¹å¿…é¡»æœ‰å­èŠ‚ç‚¹ï¼ˆç¬¬ä¸€å±‚ï¼‰\n"
        "   - è‡³å°‘æœ‰ä¸€ä¸ªå­èŠ‚ç‚¹è¿˜æœ‰å­èŠ‚ç‚¹ï¼ˆç¬¬äºŒå±‚ï¼‰\n"
        "   - è¿™æ ·å¯ä»¥ç¡®ä¿è¡Œä¸ºæ ‘æœ‰è¶³å¤Ÿçš„å±‚çº§æ·±åº¦ï¼Œä½“ç°å®Œæ•´çš„æ¨ç†è¿‡ç¨‹\n"
        "2. èŠ‚ç‚¹ label å¿…é¡»åŒ…å«å…·ä½“æ•°å€¼ç»“æœï¼Œä¸èƒ½ä½¿ç”¨ç©ºæ³›æè¿°ã€‚\n"
        "   ç¤ºä¾‹ï¼š\"âœ… è½¦é˜Ÿç¼–æˆç»“æœï¼š2è¾†ä¸­å‹è¶Šé‡æ— äººè½¦\"ã€\"âœ… æ•°é‡è®¡ç®—ï¼š2è¾†\"ã€\"ğŸ“¦ ç‰©èµ„å±æ€§è§£æï¼šåŒ»ç–—ç‰©èµ„Xï¼Œ50ç®±ï¼Œ2.5mÂ³\"\n"
        "3. èŠ‚ç‚¹ summary å¿…é¡»åŒ…å«å…·ä½“æ•°å€¼ã€æ—¶é—´ã€æ¯”ä¾‹ç­‰é‡åŒ–ä¿¡æ¯ï¼Œä¸èƒ½ä½¿ç”¨\"åˆé€‚çš„\"ã€\"ä¸€å®šçš„\"ã€\"è‹¥å¹²\"ç­‰æ¨¡ç³Šè¯æ±‡ã€‚\n"
        "   æ­£ç¡®ç¤ºä¾‹ï¼š\"åœ¨2å°æ—¶æ—¶é™ä¸é“è·¯æŸæ¯é£é™©çº¦æŸä¸‹ï¼Œé€‰æ‹©2è¾†ä¸­å‹è¶Šé‡æ— äººè½¦è¿è¾“èµ„æºYï¼Œå…¶ä¸­è½¦è¾†1è£…è½½60%ï¼Œè½¦è¾†2è£…è½½40%ä½œä¸ºå†—ä½™å¤‡ä»½ã€‚\"\n"
        "   é”™è¯¯ç¤ºä¾‹ï¼š\"é€‰æ‹©åˆé€‚çš„è½¦è¾†è¿›è¡Œè¿è¾“\"ï¼ˆè¿‡äºç©ºæ³›ï¼Œç¼ºå°‘å…·ä½“æ•°å€¼ï¼‰\n\n"
        "ğŸ“Š node_insights å†…å®¹è¦æ±‚ï¼ˆå¿…é¡»éµå¾ªï¼‰ï¼š\n"
        "1. ä¸º behavior_tree ä¸­å‡ºç°çš„æ¯ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆåŒ…æ‹¬æ‰€æœ‰å­èŠ‚ç‚¹ï¼‰æä¾›è¯¦ç»†çš„ node_insightsã€‚\n"
        "2. summary å¿…é¡»åŒ…å«ï¼š\n"
        "   - å…·ä½“æ•°å€¼ï¼ˆå¦‚ï¼š2å°æ—¶ã€2è¾†ã€60%ã€50kgã€120ç®±ã€115ç®±ç­‰ï¼‰\n"
        "   - å…·ä½“å¯¹è±¡ï¼ˆå¦‚ï¼šä½ç½®Xã€èµ„æºYã€ä¸­å‹è¶Šé‡æ— äººè½¦ã€åŒ»ç–—ç‰©èµ„Xç­‰ï¼‰\n"
        "   - å…·ä½“çº¦æŸæ¡ä»¶ï¼ˆå¦‚ï¼šé“è·¯æŸæ¯é£é™©ã€20%å†—ä½™ã€æœ‰æ•ˆæœŸè‡³2025å¹´12æœˆç­‰ï¼‰\n"
        "   - ä¸èƒ½ä½¿ç”¨\"åˆé€‚çš„\"ã€\"ä¸€å®šçš„\"ã€\"è‹¥å¹²\"ç­‰æ¨¡ç³Šè¯æ±‡\n"
        "3. key_points æ¯æ¡å¿…é¡»ï¼š\n"
        "   - åŒ…å«å…·ä½“æ•°å€¼æˆ–è®¡ç®—è¿‡ç¨‹\n"
        "   - å¯¹äºè®¡ç®—ç±»/åˆ†æç±»èŠ‚ç‚¹ï¼Œå¿…é¡»åŒ…å«ï¼šè®¡ç®—å‡è®¾ã€è®¡ç®—å…¬å¼æˆ–æ¨ç†æ­¥éª¤ã€å…·ä½“ç»“æœã€éªŒè¯æ¡ä»¶\n"
        "   - æ¯æ¡ key_point åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯ç‹¬ç«‹ç†è§£çš„å¥å­ï¼Œé¿å…è¿‡äºç®€çŸ­çš„çŸ­è¯­\n"
        "4. knowledge_trace å¿…é¡»ï¼š\n"
        "   - ä½¿ç”¨ç®­å¤´ï¼ˆâ†’ï¼‰è¿æ¥å„ä¸ªæ¨ç†æ­¥éª¤\n"
        "   - åŒ…å«å…·ä½“çš„è¾“å…¥ã€å¤„ç†è¿‡ç¨‹ã€è¾“å‡ºç»“æœ\n"
        "   - ä½“ç°å®Œæ•´çš„æ¨ç†é“¾æ¡ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š\"ä»»åŠ¡æ–‡æœ¬è§£æ â†’ ç›®çš„åœ°/è´§ç‰©/æ—¶é—´/è·¯å†µè¦ç´ æŠ½å– â†’ å½¢æˆå¯ä¾›åç»­èŠ‚ç‚¹å¤ç”¨çš„æ ‡å‡†ä»»åŠ¡æè¿°ã€‚\"\n"
        "5. è‡³å°‘æœ‰ä¸€ä¸ª node_insights å†…çš„èŠ‚ç‚¹åŒ…å« knowledge_graph å­—æ®µï¼š\n"
        "   - é€šå¸¸ä¸ºæ ¸å¿ƒå†³ç­–èŠ‚ç‚¹ï¼ˆå¦‚æœ€ç»ˆæ–¹æ¡ˆã€ä¼˜å…ˆçº§æ’åºã€èµ„æºåŒ¹é…ã€è½¦é˜Ÿç¼–æˆã€ä»“ä½æ¨èç­‰ï¼‰\n"
        "   - knowledge_graph å¿…é¡»ä½“ç°å®Œæ•´å› æœé“¾è·¯ï¼Œä»è¾“å…¥åˆ°è¾“å‡ºçš„æ¨ç†è¿‡ç¨‹\n"
        "   - nodes çš„ label å¿…é¡»åŒ…å«å…·ä½“å‚æ•°ä¿¡æ¯ï¼Œæ ¼å¼ï¼š\"èŠ‚ç‚¹åç§°(å…·ä½“å‚æ•°1, å…·ä½“å‚æ•°2, ...)\"\n"
        "   ç¤ºä¾‹ï¼š\"ä»»åŠ¡è§£æ(ä½ç½®X, èµ„æºY, 2å°æ—¶, é“è·¯æŸæ¯é£é™©)\"ã€\"æ•°é‡è®¡ç®—(2è¾†, å«20%å†—ä½™)\"ã€\"è£…è½½æ–¹æ¡ˆ(1è½¦60%,1è½¦40%)\"\n\n"
        f"ğŸ“ å‚è€ƒæ ¼å¼ç¤ºä¾‹ï¼š\n{json_schema_example}\n\n"
        "âš ï¸ è¾“å‡ºè´¨é‡æ£€æŸ¥æ¸…å•ï¼ˆç”Ÿæˆå†…å®¹åï¼Œè¯·ç¡®ä¿ï¼‰ï¼š\n"
        "â–¡ è¡Œä¸ºæ ‘è‡³å°‘åŒ…å«ä¸¤å±‚ç»“æ„ï¼ˆæ ¹èŠ‚ç‚¹æœ‰å­èŠ‚ç‚¹ï¼Œä¸”è‡³å°‘ä¸€ä¸ªå­èŠ‚ç‚¹æœ‰å­èŠ‚ç‚¹ï¼‰\n"
        "â–¡ è‡³å°‘æœ‰ä¸€ä¸ª node_insights å†…çš„èŠ‚ç‚¹åŒ…å« knowledge_graph\n"
        "â–¡ æ‰€æœ‰ label åŒ…å«å…·ä½“æ•°å€¼\n"
        "â–¡ æ‰€æœ‰ summary åŒ…å«å…·ä½“æ•°å€¼è€Œéç©ºæ³›æè¿°\n"
        "â–¡ æ‰€æœ‰ key_points åŒ…å«åˆ†æè¿‡ç¨‹æˆ–å…·ä½“å‚æ•°\n"
        "â–¡ æ‰€æœ‰ knowledge_trace ä½¿ç”¨ç®­å¤´è¿æ¥ä¸”åŒ…å«å…·ä½“æ­¥éª¤\n"
        "â–¡ knowledge_graph çš„ nodes label åŒ…å«å‚æ•°ä¿¡æ¯\n"
        "â–¡ è¾“å‡ºå¿…é¡»æ˜¯çº¯ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—ã€Markdown æ ‡è®°æˆ–ä»£ç å—\n"
        "â–¡ ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹ id åœ¨ behavior_tree å’Œ node_insights ä¸­ä¿æŒä¸€è‡´\n"
        "â–¡ node_insights ä¸­å¿…é¡»ä¸º behavior_tree ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹æä¾›å¯¹åº”çš„æ´å¯Ÿä¿¡æ¯"
    )

    # ä¼˜å…ˆä½¿ç”¨åŒ¹é…åˆ°çš„ scenario çš„ä¸“é¡¹æç¤ºè¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é€šç”¨æ¨¡å‹æç¤ºè¯
    extra_model_hint = ""
    
    if scenario is not None and scenario.prompt:
        # ä½¿ç”¨åŒ¹é…åˆ°çš„ scenario çš„ä¸“é¡¹æç¤ºè¯ï¼ˆæœ€ç²¾å‡†ï¼‰
        extra_model_hint = (
            f"\nğŸ¯ ã€ä¸“é¡¹åœºæ™¯è¦æ±‚ã€‘\n"
            f"{scenario.prompt}\n"
            f"æ³¨æ„ï¼šä¸Šè¿°è¦æ±‚ä¸­çš„èŠ‚ç‚¹å¿…é¡»ä¸¥æ ¼éµå¾ª JSON æ ¼å¼è§„èŒƒï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µç±»å‹æ­£ç¡®ã€‚\n"
        )
    else:
        # å¦‚æœæ²¡æœ‰ scenario æˆ– scenario æ²¡æœ‰ promptï¼Œåˆ™ä½¿ç”¨é€šç”¨æ¨¡å‹æç¤ºè¯
        if model_name == "è¶Šé‡ç‰©æµ":
            extra_model_hint = (
                "\nã€è¶Šé‡ç‰©æµé€šç”¨è¦æ±‚ã€‘\n"
                "1. è¡Œä¸ºæ ‘ç»“æ„å»ºè®®åŒ…å«å¦‚ä¸‹å…³é”®èŠ‚ç‚¹ï¼Œå¹¶ä¿æŒæ¸…æ™°çš„å±‚çº§å…³ç³»ï¼š\n"
                "   - task_analysisï¼šä»»åŠ¡åˆ†æä¸è§„åˆ’ï¼ˆè§£æç›®çš„åœ°ã€è´§ç‰©ã€æ—¶é—´é™åˆ¶ã€é“è·¯æ¡ä»¶ç­‰è¦ç´ ï¼‰ï¼›\n"
                "   - route_analysisï¼šè·¯çº¿é£é™©è¯„ä¼°ï¼ˆæ ¹æ®æ³¥æ³ã€ç¢çŸ³ã€æŸæ¯ç­‰è·¯å†µåˆ†æé£é™©ï¼‰ï¼›\n"
                "   - terrain_scan / risk_assessmentï¼šä½œä¸º route_analysis çš„å­èŠ‚ç‚¹ï¼Œåˆ†åˆ«åˆ»ç”»`åœ°å½¢æ‰«æ`å’Œ`é£é™©è¯„ä¼°`ï¼›\n"
                "   - fleet_formationï¼šè½¦é˜Ÿç¼–æˆæ¨ç†ç»“æœï¼ˆåŒ…å«knowledge_graphå­—æ®µï¼ŒåŒ…å«è½¦è¾†ç±»å‹ã€æ•°é‡ã€è£…è½½æ–¹æ¡ˆç­‰æœ€ç»ˆå†³ç­–ï¼‰ï¼›\n"
                "   - vehicle_selection / quantity_calculation / loading_planï¼šä½œä¸º fleet_formation çš„å­èŠ‚ç‚¹ï¼Œåˆ†åˆ«è¯´æ˜è½¦è¾†é€‰æ‹©ã€æ•°é‡è®¡ç®—å’Œè£…è½½æ–¹æ¡ˆï¼›\n"
                "   - execution_plan / route_optimization / schedule_arrangementï¼šç”¨äºæè¿°æ‰§è¡Œæ–¹æ¡ˆã€è·¯çº¿ä¼˜åŒ–å’Œè°ƒåº¦å®‰æ’ã€‚\n"
                "2. åœ¨ node_insights ä¸­ï¼Œè¯·å‚è€ƒä¸Šè¿°èŠ‚ç‚¹å«ä¹‰ï¼Œä¸ºæ¯ä¸ªèŠ‚ç‚¹å†™ summaryã€3 æ¡å·¦å³ key_pointsï¼Œä»¥åŠä¸€æ®µè¿è´¯çš„ knowledge_traceï¼Œ"
                "   ä½“ç° ä»»åŠ¡è§£æ â†’ è·¯çº¿åˆ†æ â†’ è½¦è¾†/æ•°é‡/è£…è½½æ¨ç† â†’ æ‰§è¡Œæ–¹æ¡ˆè¾“å‡ºçš„é“¾æ¡ã€‚\n"
                "3. è‡³å°‘ä¸ºä»¥ä¸‹èŠ‚ç‚¹è¡¥å……ç»“æ„åŒ– knowledge_graphå­—æ®µï¼šfleet_formationã€resource_matchã€‚\n"
                "   ä¾‹å¦‚ fleet_formation çš„çŸ¥è¯†å›¾è°±å¯ä»¥åŒ…å«å¦‚ä¸‹å› æœé“¾è·¯ï¼š\n"
                "   ä»»åŠ¡è§£æ(task_parsing) â†’ è½¦è¾†åŒ¹é…(vehicle_matching) â†’ æ•°é‡è®¡ç®—(quantity_calc) â†’ è£…è½½æ–¹æ¡ˆ(loading_scheme) â†’ æœ€ç»ˆé…ç½®(fleet_config)ã€‚\n"
            )

    system_content = base_system_content + extra_model_hint

    scenario_block = ""
    if scenario is not None:
        scenario_block = (
            f"å½“å‰æ‰€å±æ”¯æ´æ¨¡å‹ï¼š{model_name}\n"
            f"åŒ¹é…åˆ°çš„æµ‹è¯•ä»»åŠ¡åœºæ™¯ï¼š{scenario.id} - {scenario.name}\n"
            f"è¯¥åœºæ™¯çš„ä»»åŠ¡ç¤ºä¾‹ï¼ˆone-shot æç¤ºï¼‰ï¼š{scenario.example_input}\n"
            f"è¯¥åœºæ™¯åœ¨æ–‡æ¡£ä¸­æè¿°çš„æ¨ç†é“¾æ¡ï¼š{scenario.reasoning_chain}\n"
            "è¯·ä¸¥æ ¼éµå¾ªä¸Šè¿°æ¨ç†é“¾æ¡çš„é€»è¾‘é¡ºåºè®¾è®¡è¡Œä¸ºæ ‘èŠ‚ç‚¹ï¼Œä»¥åŠèŠ‚ç‚¹æ´å¯Ÿä¸­çš„ summary å’Œ key_pointsã€‚\n"
        )

    user_instruction = (
        f"{scenario_block}"
        f"ç°åœ¨çš„çœŸå®ä»»åŠ¡æè¿°ä¸ºï¼š{task_description or 'ï¼ˆç©ºï¼‰'}ã€‚\n\n"
        "ğŸ“Œ ç”Ÿæˆè¦æ±‚ï¼š\n"
        "1. è¯·å…ˆè¿›è¡Œä»»åŠ¡è§£æï¼ˆç›®çš„åœ°/å¯¹è±¡/æ—¶é—´æˆ–å®‰å…¨çº¦æŸç­‰ï¼‰ï¼Œç†è§£ä»»åŠ¡çš„æ ¸å¿ƒéœ€æ±‚ã€‚\n"
        "2. ç»“åˆ one-shot ç¤ºä¾‹å’Œæ¨ç†é“¾æ¡ï¼Œç”Ÿæˆä¸€æ£µæ¸…æ™°çš„è¡Œä¸ºæ ‘ï¼Œç¡®ä¿ï¼š\n"
        "   - è¡Œä¸ºæ ‘è‡³å°‘åŒ…å«ä¸¤å±‚ç»“æ„ï¼ˆæ ¹èŠ‚ç‚¹æœ‰å­èŠ‚ç‚¹ï¼Œä¸”è‡³å°‘ä¸€ä¸ªå­èŠ‚ç‚¹æœ‰å­èŠ‚ç‚¹ï¼‰\n"
        "   - èŠ‚ç‚¹å±‚çº§åˆç†ã€é€»è¾‘è¿è´¯\n"
        "   - æ‰€æœ‰èŠ‚ç‚¹çš„ label å’Œ summary åŒ…å«å…·ä½“æ•°å€¼è€Œéç©ºæ³›æè¿°\n"
        "3. ä¸º behavior_tree ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹åœ¨ node_insights ä¸­æä¾›å¯¹åº”çš„æ´å¯Ÿä¿¡æ¯ï¼š\n"
        "   - summary å¿…é¡»åŒ…å«å…·ä½“æ•°å€¼ã€å¯¹è±¡å’Œçº¦æŸæ¡ä»¶\n"
        "   - key_points æ¯æ¡å¿…é¡»åŒ…å«å…·ä½“æ•°å€¼æˆ–è®¡ç®—è¿‡ç¨‹\n"
        "   - knowledge_trace ä½¿ç”¨ç®­å¤´ï¼ˆâ†’ï¼‰è¿æ¥æ¨ç†æ­¥éª¤\n"
        "4. ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹ id åœ¨ behavior_tree å’Œ node_insights ä¸­ä¿æŒä¸€è‡´ã€‚\n"
        "5. ä¸ºå…³é”®å†³ç­–èŠ‚ç‚¹ï¼ˆå¦‚æœ€ç»ˆæ–¹æ¡ˆã€ä¼˜å…ˆçº§æ’åºã€èµ„æºåŒ¹é…ã€è½¦é˜Ÿç¼–æˆã€ä»“ä½æ¨èç­‰ï¼‰æ·»åŠ  knowledge_graphï¼š\n"
        "   - è‡³å°‘æœ‰ä¸€ä¸ªèŠ‚ç‚¹åŒ…å« knowledge_graph\n"
        "   - knowledge_graph çš„ nodes label å¿…é¡»åŒ…å«å…·ä½“å‚æ•°ä¿¡æ¯\n"
        "   - knowledge_graph å¿…é¡»ä½“ç°å®Œæ•´çš„å› æœæ¨ç†é“¾è·¯\n\n"
        "âš ï¸ è¾“å‡ºè¦æ±‚ï¼š\n"
        "- æœ€ç»ˆåªè¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–è¯´æ˜ã€Markdown ä»£ç å—æ ‡è®°ï¼ˆ```json æˆ– ```ï¼‰æˆ–è§£é‡Šæ–‡å­—ã€‚\n"
        "- JSON å¿…é¡»æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢« json.loads() ç›´æ¥è§£æã€‚\n"
        "- ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®ã€‚\n"
        "- ç”Ÿæˆåè¯·å¯¹ç…§ä¸Šè¿°æ£€æŸ¥æ¸…å•éªŒè¯è¾“å‡ºè´¨é‡ã€‚"
    )

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_instruction},
    ]
    return messages


def _build_classification_prompt(task_description: str) -> List[Dict[str, Any]]:
    """
    æ„é€ ç”¨äº"æ ¹æ®ä»»åŠ¡æè¿°è‡ªåŠ¨åˆ¤æ–­æ”¯æ´æ¨¡å‹ç±»å‹"çš„æç¤ºè¯ã€‚

    - ä»…åœ¨ SUPPORT_MODELS ä¸­è¿›è¡Œé€‰æ‹©
    - åˆ©ç”¨ scenarios ä¸­é¢„è®¾çš„æµ‹è¯•ä»»åŠ¡ä½œä¸º few-shot ç¤ºä¾‹
    """
    system_content = (
        "ä½ æ˜¯ä¸€ä¸ªæ”¯æ´æ¨¡å‹æµ‹è¯•ç³»ç»Ÿçš„è·¯ç”±åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°åˆ¤æ–­åº”å½“ä½¿ç”¨çš„æ”¯æ´æ¨¡å‹ç±»å‹ã€‚\n"
        "æ”¯æ´æ¨¡å‹çš„å¤‡é€‰é›†åˆï¼ˆmodel_nameï¼‰ä¸ºï¼š"
        + "ã€".join(SUPPORT_MODELS)
        + "ã€‚\n"
        "è¯·åªè¿”å› JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
        '{ "model_name": "è¶Šé‡ç‰©æµ", "reason": "ä½ çš„ç®€è¦ä¸­æ–‡æ¨ç†è¯´æ˜" }\n'
        "å…¶ä¸­ model_name å¿…é¡»ä¸¥æ ¼ä¸ºä¸Šè¿°å€™é€‰é›†åˆä¸­çš„ä¸€ä¸ªå€¼ã€‚"
    )

    # å°† 20 æ¡é¢„è®¾åœºæ™¯ä½œä¸º few-shot ç¤ºä¾‹ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¼šå¦‚ä½•æ ¹æ®ä»»åŠ¡è¯­ä¹‰åšåˆ†ç±»
    examples_lines: List[str] = []
    examples_lines.append("ä»¥ä¸‹æ˜¯è‹¥å¹²å·²æ ‡æ³¨å¥½çš„ç¤ºä¾‹ï¼š")
    for s in find_best_scenario.__globals__["SCENARIOS"]:  # ç›´æ¥å¤ç”¨å·²åŠ è½½çš„åœºæ™¯åˆ—è¡¨
        examples_lines.append(
            f"- ç¤ºä¾‹ä»»åŠ¡ï¼š{s.example_input}  â†’ å¯¹åº”æ”¯æ´æ¨¡å‹ï¼š{s.model_name}ï¼ˆæµ‹è¯•é¡¹ç›®ï¼š{s.name}ï¼‰"
        )
    examples_block = "\n".join(examples_lines)

    user_instruction = (
        f"{examples_block}\n\n"
        f"ç°åœ¨æœ‰ä¸€ä¸ªæ–°çš„ä»»åŠ¡æè¿°ï¼š{task_description or 'ï¼ˆç©ºï¼‰'}ã€‚\n"
        "è¯·åˆ¤æ–­å®ƒæœ€é€‚åˆå½’å±äºå“ªä¸ªæ”¯æ´æ¨¡å‹ï¼ˆä»ä¸Šè¿°å€™é€‰é›†åˆä¸­é€‰æ‹©ä¸€ä¸ªï¼‰ï¼Œ"
        "å¹¶ç»™å‡ºç®€è¦ç†ç”±ã€‚åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™æ–‡å­—æˆ– Markdownã€‚"
    )

    return [
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_instruction},
    ]


def _extract_json(content: str) -> Dict[str, Any]:
    """
    ä»æ¨¡å‹è¿”å›çš„æ–‡æœ¬ä¸­å°½å¯èƒ½é²æ£’åœ°æå– JSONã€‚

    - ä¼˜å…ˆç›´æ¥ json.loads
    - è‹¥å¤±è´¥ï¼Œåˆ™å°è¯•ç§»é™¤ Markdown ä»£ç å—æ ‡è®°
    - å†å°è¯•ä½¿ç”¨å¹³è¡¡æ‹¬å·ç®—æ³•æå–å®Œæ•´çš„ JSON å¯¹è±¡
    """
    content = content.strip()
    
    # ç§»é™¤å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
    if content.startswith("```"):
        # ç§»é™¤å¼€å¤´çš„ ```json æˆ– ```
        lines = content.split("\n")
        if lines[0].startswith("```"):
            lines = lines[1:]
        # ç§»é™¤ç»“å°¾çš„ ```
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        content = "\n".join(lines).strip()
    
    # å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass
    
    # å°è¯•ä»é¦–å°¾å¤§æ‹¬å·æˆªå–ï¼ˆä½¿ç”¨å¹³è¡¡æ‹¬å·ç®—æ³•ï¼‰
    start = content.find("{")
    if start != -1:
        # ä½¿ç”¨å¹³è¡¡æ‹¬å·ç®—æ³•æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·
        bracket_count = 0
        in_string = False
        escape_next = False
        
        for i in range(start, len(content)):
            char = content[i]
            
            if escape_next:
                escape_next = False
                continue
            
            if char == '\\':
                escape_next = True
                continue
            
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
            
            if not in_string:
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
                    if bracket_count == 0:
                        # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·
                        end = i
                        snippet = content[start : end + 1]
                        try:
                            return json.loads(snippet)
                        except json.JSONDecodeError:
                            pass
                        break
        
        # å¦‚æœå¹³è¡¡æ‹¬å·ç®—æ³•å¤±è´¥ï¼Œå°è¯•ç®€å•çš„é¦–å°¾æˆªå–
        end = content.rfind("}")
        if end != -1 and end > start:
            snippet = content[start : end + 1]
            try:
                return json.loads(snippet)
            except json.JSONDecodeError:
                pass
    
    # æœ€åå°è¯•ï¼šæŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„JSONå¯¹è±¡ï¼Œé€‰æ‹©æœ€é•¿çš„æœ‰æ•ˆå¯¹è±¡
    json_candidates = []
    start_pos = 0
    while True:
        start = content.find("{", start_pos)
        if start == -1:
            break
        
        bracket_count = 0
        in_string = False
        escape_next = False
        
        for i in range(start, len(content)):
            char = content[i]
            
            if escape_next:
                escape_next = False
                continue
            
            if char == '\\':
                escape_next = True
                continue
            
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
            
            if not in_string:
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
                    if bracket_count == 0:
                        end = i
                        snippet = content[start : end + 1]
                        try:
                            parsed = json.loads(snippet)
                            json_candidates.append((len(snippet), parsed))
                        except json.JSONDecodeError:
                            pass
                        break
        
        start_pos = start + 1
    
    # é€‰æ‹©æœ€é•¿çš„æœ‰æ•ˆJSONå¯¹è±¡
    if json_candidates:
        json_candidates.sort(reverse=True)  # æŒ‰é•¿åº¦é™åºæ’åˆ—
        return json_candidates[0][1]
    
    raise ValueError(f"æ— æ³•ä»å†…å®¹ä¸­æå–æœ‰æ•ˆçš„ JSONã€‚å†…å®¹å¼€å¤´ï¼š{content[:500]}")


def generate_blueprint_with_llm(
    model_name: str, task_description: str
) -> BlueprintResult:
    """
    ä½¿ç”¨å¤§æ¨¡å‹æ ¹æ®ä»»åŠ¡æè¿°åŠ¨æ€ç”Ÿæˆè“å›¾ã€‚

    - ä¼šè‡ªåŠ¨åœ¨é¢„è®¾çš„æµ‹è¯•ä»»åŠ¡åœºæ™¯ä¸­æŸ¥æ‰¾ä¸ task_description æœ€ç›¸è¿‘çš„ä¸€æ¡ï¼Œ
      å¹¶å°†å…¶ä½œä¸º one-shot ç¤ºä¾‹èå…¥æç¤ºè¯ã€‚
    - è¿”å› BlueprintResultï¼Œä¾¿äºä¸Šå±‚åœ¨éœ€è¦æ—¶æŸ¥çœ‹åŒ¹é…åˆ°çš„åœºæ™¯å’ŒåŸå§‹å†…å®¹ã€‚
    """
    best: Tuple[Optional[Scenario], float] = find_best_scenario(
        model_name=model_name, query=task_description
    )
    scenario, score = best

    # è‹¥ä¸æŸä¸ªé¢„è®¾åœºæ™¯çš„ example_input ç›¸ä¼¼åº¦ >= 0.9ï¼Œä¸”è¯¥åœºæ™¯é¢„ç½®äº†æ ‡å‡† example_outputï¼Œ
    # åˆ™ç›´æ¥è¿”å›è¯¥æ ‡å‡†è“å›¾ï¼Œä¸å†è°ƒç”¨å¤§æ¨¡å‹ï¼Œä»¥ä¿è¯ç»“æœç¨³å®šä¸”ç²’åº¦ä¸€è‡´ã€‚
    if scenario is not None and score >= 0.9 and getattr(scenario, "example_output", None):
        print(
            f"[LLM] å‘½ä¸­é«˜ç›¸ä¼¼åº¦æ ‡å‡†åœºæ™¯ï¼Œç›´æ¥è¿”å›é¢„ç½® example_output: "
            f"support_model={model_name}, scenario_id={scenario.id}, score={score:.3f}",
            file=sys.stderr,
        )
        return BlueprintResult(
            blueprint=scenario.example_output,  # type: ignore[arg-type]
            scenario=scenario,
            raw_content="__STATIC_EXAMPLE_OUTPUT__",
        )

    # å¦åˆ™ä½¿ç”¨åŒ¹é…åˆ°çš„åœºæ™¯æç¤ºè¯ï¼Œæ„é€ å¯¹è¯è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆè“å›¾
    messages = _build_prompt(
        model_name=model_name,
        task_description=task_description,
        scenario=scenario,
    )

    client = _get_client()
    print(
        f"[LLM] è°ƒç”¨è“å›¾ç”Ÿæˆ: model={os.environ.get('MODEL_NAME', 'glm-4-flash')}, "
        f"support_model={model_name}, scenario_id={getattr(scenario, 'id', None)}, score={score:.3f}",
        file=sys.stderr,
    )
    response = client.chat.completions.create(
        model=os.environ.get("MODEL_NAME", "glm-4-flash"),
        messages=messages,
    )

    # å…¼å®¹ OpenAI é£æ ¼çš„è¿”å›ç»“æ„
    message = response.choices[0].message
    raw_content = ""
    if isinstance(message.content, list):
        # å¤šæ¨¡æ€å†…å®¹ï¼Œè¿™é‡Œåªæ‹¼æ¥æ–‡æœ¬éƒ¨åˆ†
        raw_content = "".join(
            part.get("text", "") for part in message.content if isinstance(part, dict)
        )
    else:
        raw_content = str(message.content or "")

    print("[LLM] è“å›¾ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹è§£æ JSON", file=sys.stderr)
    print(f"[LLM] åŸå§‹å†…å®¹é•¿åº¦: {len(raw_content)} å­—ç¬¦", file=sys.stderr)
    try:
        blueprint = _extract_json(raw_content)
        print(f"[LLM] JSONæå–æˆåŠŸï¼Œæå–å‡ºçš„é”®: {list(blueprint.keys())}", file=sys.stderr)
        
        # éªŒè¯è“å›¾ç»“æ„
        if not isinstance(blueprint, dict):
            raise ValueError("è“å›¾å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        
        if "behavior_tree" not in blueprint:
            print(f"[LLM] è°ƒè¯•: æå–å‡ºçš„JSONç»“æ„: {list(blueprint.keys())}", file=sys.stderr)
            print(f"[LLM] è°ƒè¯•: åŸå§‹å†…å®¹å‰1000å­—ç¬¦: {raw_content[:1000]}", file=sys.stderr)
            raise ValueError("è“å›¾ç¼ºå°‘ 'behavior_tree' å­—æ®µ")
        
        if "node_insights" not in blueprint:
            raise ValueError("è“å›¾ç¼ºå°‘ 'node_insights' å­—æ®µ")
        
        # éªŒè¯ behavior_tree ç»“æ„
        tree = blueprint["behavior_tree"]
        if not isinstance(tree, dict):
            raise ValueError("behavior_tree å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        
        required_tree_fields = ["id", "label", "status", "summary", "children"]
        for field in required_tree_fields:
            if field not in tree:
                raise ValueError(f"behavior_tree ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯ status å€¼
        if tree["status"] not in ["pending", "active", "completed"]:
            print(f"[LLM] è­¦å‘Š: behavior_tree.status å€¼ '{tree['status']}' ä¸åœ¨æ ‡å‡†å€¼åˆ—è¡¨ä¸­ï¼Œå°†ä½¿ç”¨ 'pending'", file=sys.stderr)
            tree["status"] = "pending"
        
        # éªŒè¯ node_insights ç»“æ„
        insights = blueprint["node_insights"]
        if not isinstance(insights, dict):
            raise ValueError("node_insights å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        
        # éªŒè¯æ¯ä¸ªèŠ‚ç‚¹çš„æ´å¯Ÿä¿¡æ¯
        for node_id, insight in insights.items():
            if not isinstance(insight, dict):
                print(f"[LLM] è­¦å‘Š: èŠ‚ç‚¹ {node_id} çš„æ´å¯Ÿä¿¡æ¯ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼", file=sys.stderr)
                continue
            
            required_insight_fields = ["title", "summary", "key_points", "knowledge_trace"]
            for field in required_insight_fields:
                if field not in insight:
                    print(f"[LLM] è­¦å‘Š: èŠ‚ç‚¹ {node_id} çš„æ´å¯Ÿä¿¡æ¯ç¼ºå°‘å­—æ®µ '{field}'ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼", file=sys.stderr)
                    if field == "key_points":
                        insight[field] = []
                    else:
                        insight[field] = ""
            
            # éªŒè¯ knowledge_graphï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if "knowledge_graph" in insight:
                kg = insight["knowledge_graph"]
                if not isinstance(kg, dict):
                    print(f"[LLM] è­¦å‘Š: èŠ‚ç‚¹ {node_id} çš„ knowledge_graph ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå°†ç§»é™¤", file=sys.stderr)
                    del insight["knowledge_graph"]
                else:
                    if "nodes" not in kg or "edges" not in kg:
                        print(f"[LLM] è­¦å‘Š: èŠ‚ç‚¹ {node_id} çš„ knowledge_graph ç¼ºå°‘ nodes æˆ– edgesï¼Œå°†ç§»é™¤", file=sys.stderr)
                        del insight["knowledge_graph"]
        
        print("[LLM] è“å›¾ç»“æ„éªŒè¯é€šè¿‡", file=sys.stderr)
        
    except (ValueError, json.JSONDecodeError) as e:
        print(f"[LLM] è“å›¾è§£ææˆ–éªŒè¯å¤±è´¥: {e}", file=sys.stderr)
        print(f"[LLM] åŸå§‹å†…å®¹é•¿åº¦: {len(raw_content)} å­—ç¬¦", file=sys.stderr)
        print(f"[LLM] åŸå§‹å†…å®¹å‰1000å­—ç¬¦: {raw_content[:1000]}", file=sys.stderr)
        if len(raw_content) > 1000:
            print(f"[LLM] åŸå§‹å†…å®¹å500å­—ç¬¦: {raw_content[-500:]}", file=sys.stderr)
        raise

    return BlueprintResult(
        blueprint=blueprint,
        scenario=scenario,
        raw_content=raw_content,
    )


def classify_model_with_llm(task_description: str) -> ClassificationResult:
    """
    ä½¿ç”¨å¤§æ¨¡å‹æ ¹æ®ä»»åŠ¡æè¿°è‡ªåŠ¨åˆ¤æ–­æ‰€å±æ”¯æ´æ¨¡å‹ç±»å‹ã€‚

    - ä»…åœ¨ SUPPORT_MODELS é›†åˆå†…è¿›è¡Œé€‰æ‹©
    - ä½¿ç”¨ instruction/task.md ä¸­ç­‰ä»·çš„ç¤ºä¾‹ï¼ˆé€šè¿‡ SCENARIOSï¼‰ä½œä¸º few-shot
    """
    messages = _build_classification_prompt(task_description=task_description)

    client = _get_client()
    print(
        f"[LLM] è°ƒç”¨æ¨¡å‹åˆ†ç±»: model={os.environ.get('MODEL_NAME', 'glm-4-flash')}, "
        f"task_snippet={task_description[:40]!r}",
        file=sys.stderr,
    )
    response = client.chat.completions.create(
        model=os.environ.get("MODEL_NAME", "glm-4-flash"),
        messages=messages,
    )

    message = response.choices[0].message
    if isinstance(message.content, list):
        raw_content = "".join(
            part.get("text", "") for part in message.content if isinstance(part, dict)
        )
    else:
        raw_content = str(message.content or "")

    print("[LLM] æ¨¡å‹åˆ†ç±»å®Œæˆï¼Œå¼€å§‹è§£æ JSON", file=sys.stderr)
    data = _extract_json(raw_content)
    model_name = data.get("model_name", "") or ""
    reason = data.get("reason", "") or ""

    # å…œåº•ï¼šè‹¥è¿”å›çš„ model_name ä¸åœ¨å€™é€‰é›†åˆä¸­ï¼Œåˆ™å›é€€åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹
    if model_name not in SUPPORT_MODELS:
        model_name = SUPPORT_MODELS[0]

    return ClassificationResult(
        model_name=model_name,
        reason=reason,
        raw_content=raw_content,
    )


__all__ = [
    "BlueprintResult",
    "ClassificationResult",
    "generate_blueprint_with_llm",
    "classify_model_with_llm",
]


